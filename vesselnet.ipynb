{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/albumentations-team/albumentations.git","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:30:44.691247Z","iopub.execute_input":"2021-12-30T05:30:44.691530Z","iopub.status.idle":"2021-12-30T05:30:59.014123Z","shell.execute_reply.started":"2021-12-30T05:30:44.691493Z","shell.execute_reply":"2021-12-30T05:30:59.013279Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Check the GPU being used","metadata":{}},{"cell_type":"code","source":"# setting device on GPU if available, else CPU\nimport torch\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)\nprint()\n\n#Additional Info when using cuda\nif device.type == 'cuda':\n    print(torch.cuda.get_device_name(0))\n    print('Memory Usage:')\n    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:30:59.017181Z","iopub.execute_input":"2021-12-30T05:30:59.017460Z","iopub.status.idle":"2021-12-30T05:31:03.373522Z","shell.execute_reply.started":"2021-12-30T05:30:59.017423Z","shell.execute_reply":"2021-12-30T05:31:03.372695Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\ntrain_img_dir= '../input/vesselnet-code/Data/Data/CHASE/CHASE_1000/train/image'\ntrain_label_dir= '../input/vesselnet-code/Data/Data/CHASE/CHASE_1000/train/label'\n\n#checking len of images data set\ntrain_img_iter=sorted(glob.glob(train_label_dir+'/*'))\nprint(len(train_img_iter))\n#checking len of mask data set\n\nlabel_img_iter=sorted(glob.glob(train_img_dir+'/*'))\nprint(len(label_img_iter))","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:31:03.375378Z","iopub.execute_input":"2021-12-30T05:31:03.375879Z","iopub.status.idle":"2021-12-30T05:31:03.753202Z","shell.execute_reply.started":"2021-12-30T05:31:03.375837Z","shell.execute_reply":"2021-12-30T05:31:03.752399Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Dataloader","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\n\n\nfrom PIL import Image\nfrom torch.utils.data import Dataset\nfrom pathlib import Path\n\nclass IMG_Dataset(Dataset):\n    def __init__(self, image_dir, mask_dir, transform = None):\n        self.image_dir = image_dir\n        self.mask_dir = mask_dir\n        self.transform = transform\n        self.images = os.listdir(image_dir)\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, index):\n        img_path = os.path.join(self.image_dir, self.images[index])\n        mask_path = os.path.join(self.mask_dir, self.images[index].replace('.jpg', '_mask.png'))\n        image = np.array(Image.open(img_path).convert('RGB'), dtype=np.float32)\n        mask = np.array(Image.open(mask_path).convert('L'), dtype=np.float32)\n        mask[mask == 255.0] = 1.0\n\n        if self.transform is  not None:\n            augmentations = self.transform(image = image, mask = mask)\n            image = augmentations[\"image\"]\n            mask = augmentations[\"mask\"]\n\n        return image, mask","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:31:03.755221Z","iopub.execute_input":"2021-12-30T05:31:03.755976Z","iopub.status.idle":"2021-12-30T05:31:03.766322Z","shell.execute_reply.started":"2021-12-30T05:31:03.755935Z","shell.execute_reply":"2021-12-30T05:31:03.765345Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Utils\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision\n\nfrom torch.utils.data import DataLoader\n# \n# from Datasets.dataloader import IMG_Dataset\n\n\n\ndef get_loaders(\n        train_dir,\n        train_mask_dir,\n        val_dir,\n        val_mask_dir,\n        batch_size,\n        train_transform,\n        val_transform,\n        num_workers=4,\n        pin_memory=True\n):\n    train_dataset = IMG_Dataset(\n        image_dir=train_dir,\n        mask_dir=train_mask_dir,\n        transform=train_transform\n    )\n\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        pin_memory=pin_memory,\n        shuffle=True\n    )\n\n    val_dataset = IMG_Dataset(\n        image_dir=val_dir,\n        mask_dir=val_mask_dir,\n        transform=val_transform\n    )\n\n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        pin_memory=pin_memory,\n        shuffle=True\n    )\n\n    return train_loader, val_loader\n\n\ndef save_checkpoint(state, filename=\"Vessel_Net_checkpoint.pth.tar\"):\n    print(\"=> Saving checkpoint\")\n    torch.save(state, filename)\n\n\ndef load_checkpoint(checkpoint, model):\n    print(\"=> Loading checkpoint\")\n    model.load_state_dict(checkpoint['state_dict'])\n\n    epoch = checkpoint['epoch']\n\n    return epoch\n\n\ndef save_predictions_as_imgs(loader, model, folder=\"saved_images/\", device=\"cuda\"):\n    model.eval()\n    for idx, (x, y) in enumerate(loader):\n        x = x.to(device=device)\n        with torch.no_grad():\n            preds = torch.sigmoid(model(x))\n            preds = (preds > 0.5).float()\n        torchvision.utils.save_image(preds, f\"{folder}/pred/{idx}.png\")\n        torchvision.utils.save_image(y.unsqueeze(1), f\"{folder}/truth_labels/{idx}.png\")\n    model.train()","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:31:03.767614Z","iopub.execute_input":"2021-12-30T05:31:03.768650Z","iopub.status.idle":"2021-12-30T05:31:04.034573Z","shell.execute_reply.started":"2021-12-30T05:31:03.768611Z","shell.execute_reply":"2021-12-30T05:31:04.033838Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nprediction = pd.DataFrame(\n    columns=['Epoch_no', 'Val_Accuracy', 'Val_IoU', 'Val_Dice', 'Val_f1_score', 'Val_Precision', 'Val_Recall',\n             'Val_Specificity', 'Train_Accuracy', 'Train_IoU', 'Train_Dice', 'Train_f1_scorVal_e', 'Train_Precision',\n             'Train_Recall', 'Train_Specificity'])","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:31:04.035923Z","iopub.execute_input":"2021-12-30T05:31:04.036203Z","iopub.status.idle":"2021-12-30T05:31:04.047837Z","shell.execute_reply.started":"2021-12-30T05:31:04.036171Z","shell.execute_reply":"2021-12-30T05:31:04.047020Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Mertic result in dataframe","metadata":{}},{"cell_type":"code","source":"def adding_metrics(epoch_no, train_accuracy, val_accuracy, train_iou, val_iou, train_dice, val_dice, train_f1_score,\n                   val_f1_score, train_precision, val_precision, train_recall, val_recall, train_specificity,\n                   val_specificity, train_mcc, val_mcc, train_loss, val_loss, load_model, metrics_dir):\n    global prediction\n    if bool(load_model):\n        prediction = pd.read_csv(metrics_dir, index_col=False)\n\n    new_row = {'Epoch_no': epoch_no,\n\n               'Val_Accuracy': val_accuracy,\n               'Val_IoU': val_iou,\n               'Val_Dice': val_dice,\n               'Val_f1_score': val_f1_score,\n               'Val_Precision': val_precision,\n               'Val_Recall': val_recall,\n               'Val_Specificity': val_specificity,\n               'Val_MCC': val_mcc,\n\n               'Train_Accuracy': train_accuracy,\n               'Train_IoU': train_iou,\n               'Train_Dice': train_dice,\n               'Train_f1_score': train_f1_score,\n               'Train_Precision': train_precision,\n               'Train_Recall': train_recall,\n               'Train_Specificity': train_specificity,\n               'Train_MCC': train_mcc,\n\n               'Train_loss': train_loss,\n               'Val_loss': val_loss,\n               }\n    prediction = prediction.append(new_row, ignore_index=True)\n    convert_to_csv(prediction, metrics_dir)\n    return prediction","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:31:04.049507Z","iopub.execute_input":"2021-12-30T05:31:04.049839Z","iopub.status.idle":"2021-12-30T05:31:04.060724Z","shell.execute_reply.started":"2021-12-30T05:31:04.049801Z","shell.execute_reply":"2021-12-30T05:31:04.059740Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Testing of metrics scripts","metadata":{}},{"cell_type":"code","source":"import numpy\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass DiceLoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(DiceLoss, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1):\n        # comment out if your model contains a sigmoid or equivalent activation layer\n        inputs = F.sigmoid(inputs)\n\n        # flatten label and prediction tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n\n        intersection = (inputs * targets).sum()\n        dice = (2. * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n        \n        return 1 - dice\n\n\nclass DiceBCELoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(DiceBCELoss, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1):\n        # comment out if your model contains a sigmoid or equivalent activation layer\n        inputs = F.sigmoid(inputs)\n\n        # flatten label and prediction tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n\n        intersection = (inputs * targets).sum()\n        dice_loss = 1 - (2. * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n        Dice_BCE = BCE + dice_loss\n\n        return Dice_BCE\n\n\nclass IoULoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(IoULoss, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1):\n        # comment out if your model contains a sigmoid or equivalent activation layer\n        inputs = F.sigmoid(inputs)\n\n        # flatten label and prediction tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n\n        # intersection is equivalent to True Positive count\n        # union is the mutually inclusive area of all labels & predictions\n        intersection = (inputs * targets).sum()\n        total = (inputs + targets).sum()\n        union = total - intersection\n\n        IoU = (intersection + smooth) / (union + smooth)\n\n        return 1 - IoU\n\n\n# Focal Loss\n\n# PyTorch\nALPHA = 0.8\nGAMMA = 2\n\n\nclass FocalLoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(FocalLoss, self).__init__()\n\n    def forward(self, inputs, targets, alpha=ALPHA, gamma=GAMMA, smooth=1):\n        # comment out if your model contains a sigmoid or equivalent activation layer\n        inputs = F.sigmoid(inputs)\n\n        # flatten label and prediction tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n\n        # first compute binary cross-entropy\n        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n        BCE_EXP = torch.exp(-BCE)\n        focal_loss = alpha * (1 - BCE_EXP) ** gamma * BCE\n\n        return focal_loss\n\n\n# Tversky Loss\nALPHA = 0.5\nBETA = 0.5\n\n\nclass TverskyLoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(TverskyLoss, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1, alpha=ALPHA, beta=BETA):\n        # comment out if your model contains a sigmoid or equivalent activation layer\n        inputs = F.sigmoid(inputs)\n\n        # flatten label and prediction tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n\n        # True Positives, False Positives & False Negatives\n        TP = (inputs * targets).sum()\n        FP = ((1 - targets) * inputs).sum()\n        FN = (targets * (1 - inputs)).sum()\n\n        Tversky = (TP + smooth) / (TP + alpha * FP + beta * FN + smooth)\n\n        return 1 - Tversky\n\n\n# Focal Tversky Loss\nALPHA = 0.5\nBETA = 0.5\nGAMMA = 1\n\n\nclass FocalTverskyLoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(FocalTverskyLoss, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1, alpha=ALPHA, beta=BETA, gamma=GAMMA):\n        # comment out if your model contains a sigmoid or equivalent activation layer\n        inputs = F.sigmoid(inputs)\n\n        # flatten label and prediction tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n\n        # True Positives, False Positives & False Negatives\n        TP = (inputs * targets).sum()\n        FP = ((1 - targets) * inputs).sum()\n        FN = (targets * (1 - inputs)).sum()\n\n        Tversky = (TP + smooth) / (TP + alpha * FP + beta * FN + smooth)\n        FocalTversky = (1 - Tversky) ** gamma\n\n        return FocalTversky\n\n\n\n# Combo Loss\nALPHA = 0.5  # < 0.5 penalises FP more, > 0.5 penalises FN more\nCE_RATIO = 0.5  # weighted contribution of modified CE loss compared to Dice loss\n\n\nclass ComboLoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(ComboLoss, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1, alpha=ALPHA, beta=BETA, eps=1e-9):\n        # flatten label and prediction tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n\n        # True Positives, False Positives & False Negatives\n        intersection = (inputs * targets).sum()\n        dice = (2. * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n\n        inputs = torch.clamp(inputs, eps, 1.0 - eps)\n        out = - (ALPHA * ((targets * torch.log(inputs)) + ((1 - ALPHA) * (1.0 - targets) * torch.log(1.0 - inputs))))\n        weighted_ce = out.mean(-1)\n        combo = (CE_RATIO * weighted_ce) - ((1 - CE_RATIO) * dice)\n\n        return combo","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:31:04.062122Z","iopub.execute_input":"2021-12-30T05:31:04.062511Z","iopub.status.idle":"2021-12-30T05:31:04.093690Z","shell.execute_reply.started":"2021-12-30T05:31:04.062466Z","shell.execute_reply":"2021-12-30T05:31:04.092682Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport torchmetrics\nimport torchmetrics.functional\nimport pandas as pd\nfrom sklearn import datasets, metrics\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom torch._C import _valgrind_toggle\n\nstep = 0\n\n\ndef dice_score(preds, y):\n    return (2 * (preds * y).sum()) / (preds + y).sum() + 1e-8\n\n\ndef num_correct_pixels(preds, y):\n    return (preds == y).sum()\n\n\ndef num_total_pixels(preds):\n    return torch.numel(preds)\n\n\ndef accuracy_score(num_correct, num_pixels):\n    return num_correct / num_pixels * 100\n\n\ndef iou(preds, y):\n    preds = preds.type(torch.int)\n    y = y.type(torch.int)\n    intersection = np.logical_and(y, preds)\n    union = np.logical_or(y, preds)\n    iou_score = intersection.sum() / union.sum()\n    return iou_score\n\n\ndef precision(preds, y):\n    return torchmetrics.functional.precision(preds, y, num_classes=2, mdmc_average='global')\n\n\ndef recall(preds, y):\n    return torchmetrics.functional.recall(preds, y, num_classes=2, mdmc_average='global')\n\n\ndef f1(preds, y):\n    return torchmetrics.functional.f1(preds, y, num_classes=2, mdmc_average='global')\n\n\ndef specificity(preds, y):\n    return torchmetrics.functional.specificity(preds, y, num_classes=2, mdmc_average='global')\n\n\ndef mcc(preds, y):\n    return torchmetrics.functional.matthews_corrcoef(preds, y, num_classes=2)\n\n\ndef make_csv_copy(metrics_dir, prev_metrics_csv_dir):\n    metrics_df_old = pd.read_csv(prev_metrics_csv_dir, index_col=False)\n    convert_to_csv(metrics_df_old, metrics_dir)\n\n\ndef check_metrics(train_loader, val_loader, model, writer, epoch_no,\n                  last_epoch, loss_fn, train_loss, load_model,\n                  device=\"cuda\", metrics_dir='./new_metrics.csv',\n                  prev_metrics_csv_dir='./prev_metric.csv'):\n    # global variables definitions\n    global step\n    global metrics_dir_path\n    metrics_dir_path = metrics_dir\n    batch_num_correct = 0\n    batch_num_pixels = 0\n    val_batch_dice_score = 0\n    val_total_iou_score = 0\n    val_total_precision = 0\n    val_total_recall = 0\n    val_total_f1 = 0\n    val_total_specificity = 0\n    val_total_mcc = 0\n\n    if load_model == True:\n        if (not os.path.isfile(metrics_dir)):\n            make_csv_copy(metrics_dir, prev_metrics_csv_dir)\n\n    # start of model evaluation\n    model.eval()\n    with torch.no_grad():\n        for x, y in val_loader:\n            x = x.to(device)  # storing the input image\n            y = y.to(device).unsqueeze(1)  # storing the original mask\n            # converting the predictions to a binary map\n            preds = torch.sigmoid(model(x))\n            predictions = model(x)\n            val_loss = loss_fn(predictions, y).item()\n\n            batch_num_pixels += num_total_pixels((preds > 0.5).float())\n            y, preds = y.cpu(), (preds > 0.5).float().cpu()\n\n            batch_num_correct += num_correct_pixels((preds > 0.5).float(), y)\n            val_batch_dice_score += dice_score((preds > 0.5).float(), y)\n            val_total_iou_score += iou((preds > 0.5).float(), y)\n\n            y = y.type(torch.int)\n            val_total_f1 += f1((preds > 0.5).float().type(torch.int), y)\n            val_total_precision += precision((preds > 0.5).float().type(torch.int), y)\n            val_total_recall += recall((preds > 0.5).float().type(torch.int), y)\n            val_total_specificity += specificity((preds > 0.5).float().type(torch.int), y)\n            val_total_mcc += mcc((preds > 0.5).float().type(torch.int), y)\n\n    val_acc = accuracy_score(batch_num_correct, batch_num_pixels)\n    writer[\"writer\"].add_scalar(\"Training Accuracy\", val_acc, global_step=step)\n    step += 1\n    print('VALIDATION SCORES')\n    print(f\"Got {batch_num_correct}/{batch_num_pixels} with val_acc {val_acc}\")\n\n    print(f\"mean IoU score: {val_total_iou_score / len(val_loader)}\")\n\n    print(f\"mean Dice Score: {val_batch_dice_score / len(val_loader)}\")\n\n    print(f\"torch-metrics mean f1_score: {val_total_f1 / len(val_loader)}\")\n\n    print(f\"torch-metrics mean precision: {val_total_precision / len(val_loader)}\")\n\n    print(f\"torch-metrics mean recall: {val_total_recall / len(val_loader)}\")\n\n    print(f\"torch-metrics mean specificity: {val_total_specificity / len(val_loader)}\")\n\n    print(f\"Custom MCC metrics value:{val_total_mcc / len(val_loader)}\")\n\n    # global variables definitions\n    batch_num_correct = 0\n    batch_num_pixels = 0\n    train_batch_dice_score = 0\n    train_total_iou_score = 0\n    train_total_precision = 0\n    train_total_recall = 0\n    train_total_f1 = 0\n    train_total_specificity = 0\n    train_total_mcc = 0\n    # start of model evaluation\n    model.eval()\n    with torch.no_grad():\n        for x, y in train_loader:\n            x = x.to(device)  # storing the input image\n            y = y.to(device).unsqueeze(1)  # storing the original mask\n            # converting the predictions to a binary map\n            preds = torch.sigmoid(model(x))\n            predictions = model(x)\n            # train_loss = loss_fn(predictions, y).item()\n\n            batch_num_pixels += num_total_pixels((preds > 0.5).float())\n            y, preds = y.cpu(), (preds > 0.5).float().cpu()\n\n            batch_num_correct += num_correct_pixels((preds > 0.5).float(), y)\n            train_batch_dice_score += dice_score((preds > 0.5).float(), y)\n            train_total_iou_score += iou((preds > 0.5).float(), y)\n\n            y = y.type(torch.int)\n            train_total_f1 += f1((preds > 0.5).float().type(torch.int), y)\n            train_total_precision += precision((preds > 0.5).float().type(torch.int), y)\n            train_total_recall += recall((preds > 0.5).float().type(torch.int), y)\n            train_total_specificity += specificity((preds > 0.5).float().type(torch.int), y)\n            train_total_mcc += mcc((preds > 0.5).float().type(torch.int), y)\n\n    train_acc = accuracy_score(batch_num_correct, batch_num_pixels)\n\n    print('TRAINING SCORES')\n\n    print(f\"Got {batch_num_correct}/{batch_num_pixels} with train_acc {train_acc}\")\n\n    print(f\"mean IoU score: {train_total_iou_score / len(train_loader)}\")\n\n    print(f\"mean Dice Score: {train_batch_dice_score / len(train_loader)}\")\n\n    print(f\"torch-metrics mean f1_score: {train_total_f1 / len(train_loader)}\")\n\n    print(f\"torch-metrics mean precision: {train_total_precision / len(train_loader)}\")\n\n    print(f\"torch-metrics mean recall: {train_total_recall / len(train_loader)}\")\n\n    print(f\"torch-metrics mean specificity: {train_total_specificity / len(train_loader)}\")\n\n    print(f\"Custom MCC metrics value:{train_total_mcc / len(train_loader)}\")\n\n    # Adding Metrics to CSV\n    print(adding_metrics(epoch_no=int(epoch_no),\n\n                         val_accuracy=val_acc.detach().cpu().numpy(),\n                         val_iou=(val_total_iou_score.detach().cpu().numpy() / len(val_loader)),\n                         val_dice=(val_batch_dice_score.detach().cpu().numpy() / len(val_loader)),\n                         val_f1_score=(val_total_f1.detach().cpu().numpy() / len(val_loader)),\n                         val_precision=(val_total_precision.detach().cpu().numpy() / len(val_loader)),\n                         val_recall=(val_total_recall.detach().cpu().numpy() / len(val_loader)),\n                         val_specificity=(val_total_specificity.detach().cpu().numpy() / len(val_loader)),\n                         val_mcc=(val_total_mcc.detach().cpu().numpy() / len(val_loader)),\n\n                         train_accuracy=train_acc.detach().cpu().numpy(),\n                         train_iou=(train_total_iou_score.detach().cpu().numpy() / len(train_loader)),\n                         train_dice=(train_batch_dice_score.detach().cpu().numpy() / len(train_loader)),\n                         train_f1_score=(train_total_f1.detach().cpu().numpy() / len(train_loader)),\n                         train_precision=(train_total_precision.detach().cpu().numpy() / len(train_loader)),\n                         train_recall=(train_total_recall.detach().cpu().numpy() / len(train_loader)),\n                         train_specificity=(train_total_specificity.detach().cpu().numpy() / len(train_loader)),\n                         train_mcc=(train_total_mcc.detach().cpu().numpy() / len(train_loader)),\n\n                         train_loss=train_loss,\n                         val_loss=val_loss,\n\n                         load_model=load_model,\n                         metrics_dir=metrics_dir,\n                         )\n          )\n\n    # Plotting the ROC and Precision vs recall curves\n    preds = preds.numpy().ravel()\n    y = y.numpy().ravel()\n#    Results_dataframe = pd.read_csv(metrics_dir, index_col=False)\n#     plotting_metrics(Results_dataframe)\n#     plot_loss(Results_dataframe)\n    roc_curve_plot(y, preds)\n    precision_recall_curve_plot(y, preds)\n    model.train()  # end of model evaluation\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:55:07.197347Z","iopub.execute_input":"2021-12-30T05:55:07.197664Z","iopub.status.idle":"2021-12-30T05:55:07.240216Z","shell.execute_reply.started":"2021-12-30T05:55:07.197630Z","shell.execute_reply":"2021-12-30T05:55:07.239386Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from sklearn import datasets, metrics\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef roc_curve_plot(y_true, y_preds):\n    \n    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_preds)\n    AUC_ROC = metrics.roc_auc_score(y_true, y_preds)\n    # test_integral = np.trapz(tpr,fpr) #trapz is numpy integration\n    print (\"\\nArea under the ROC curve: \" +str(AUC_ROC))\n    roc_curve =plt.figure()\n    plt.plot(fpr,tpr,'-',label='Area Under the Curve (AUC = %0.4f)' % AUC_ROC)\n    plt.title('ROC curve')\n    plt.xlabel(\"FPR (False Positive Rate)\")\n    plt.ylabel(\"TPR (True Positive Rate)\")\n    plt.legend(loc=\"lower right\")\n    \n    plt.savefig('./metrics_plots/roc_curve_plot.png', dpi=300, bbox_inches='tight')\n    plt.close()\n\n    \ndef precision_recall_curve_plot(y_true, y_preds):\n    \n    precision, recall, thresholds = metrics.precision_recall_curve(y_true, y_preds)\n    precision = np.fliplr([precision])[0]  #so the array is increasing (you won't get negative AUC)\n    recall = np.fliplr([recall])[0]  #so the array is increasing (you won't get negative AUC)\n    AUC_prec_rec = np.trapz(precision,recall)\n    print (\"\\nArea under Precision-Recall curve: \" +str(AUC_prec_rec))\n    prec_rec_curve = plt.figure()\n    plt.plot(recall,precision,'-',label='Area Under the Curve (AUC = %0.4f)' % AUC_prec_rec)\n    plt.title('Precision - Recall curve')\n    plt.xlabel(\"Recall\")\n    plt.ylabel(\"Precision\")\n    plt.legend(loc=\"lower right\")\n    \n    plt.savefig('./metrics_plots/precision_recall_curve_plot.png', dpi=300, bbox_inches='tight')\n    plt.close()\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:31:04.407371Z","iopub.execute_input":"2021-12-30T05:31:04.407645Z","iopub.status.idle":"2021-12-30T05:31:04.417427Z","shell.execute_reply.started":"2021-12-30T05:31:04.407612Z","shell.execute_reply":"2021-12-30T05:31:04.416568Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# y = np.array([1, 1, 2, 2])\n# scores = np.array([0.1, 0.4, 0.35, 0.8])\n# roc_curve_plot(y,scores)\n# precision_recall_curve_plot(y,scores)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:31:04.418770Z","iopub.execute_input":"2021-12-30T05:31:04.419137Z","iopub.status.idle":"2021-12-30T05:31:04.428952Z","shell.execute_reply.started":"2021-12-30T05:31:04.419101Z","shell.execute_reply":"2021-12-30T05:31:04.428220Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"## Model def","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:31:04.430152Z","iopub.execute_input":"2021-12-30T05:31:04.430555Z","iopub.status.idle":"2021-12-30T05:31:04.437374Z","shell.execute_reply.started":"2021-12-30T05:31:04.430519Z","shell.execute_reply":"2021-12-30T05:31:04.436530Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torchvision.transforms.functional as TF\n\n\nclass DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(DoubleConv, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n                      kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n            nn.Dropout2d(p=0.1, inplace=True),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n\n            nn.Conv2d(in_channels=out_channels, out_channels=out_channels,\n                      kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n\n            nn.Dropout2d(p=0.1, inplace=True),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n    def forward(self, x):\n        return self.conv(x)\n\n\nclass SingleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(SingleConv, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n                      kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n            nn.Dropout2d(p=0.1, inplace=True),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n        )\n    def forward(self, x):\n        x=self.conv(x)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:31:04.438693Z","iopub.execute_input":"2021-12-30T05:31:04.438906Z","iopub.status.idle":"2021-12-30T05:31:04.453264Z","shell.execute_reply.started":"2021-12-30T05:31:04.438880Z","shell.execute_reply":"2021-12-30T05:31:04.452352Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom torch import nn\nfrom torch.nn import init\n\n\nclass ChannelAttention(nn.Module):\n    def __init__(self, channel, reduction=16):\n        super().__init__()\n        self.maxpool = nn.AdaptiveMaxPool2d(1)\n        self.avgpool = nn.AdaptiveAvgPool2d(1)\n        self.se = nn.Sequential(\n            nn.Conv2d(channel, channel // reduction, 1, bias=False),\n            nn.ReLU(),\n            nn.Conv2d(channel // reduction, channel, 1, bias=False)\n        )\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        max_result = self.maxpool(x)\n        avg_result = self.avgpool(x)\n        max_out = self.se(max_result)\n        avg_out = self.se(avg_result)\n        output = self.sigmoid(max_out + avg_out)\n        return output\n\n\nclass SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super().__init__()\n        self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=kernel_size // 2)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        max_result, _ = torch.max(x, dim=1, keepdim=True)\n        avg_result = torch.mean(x, dim=1, keepdim=True)\n        result = torch.cat([max_result, avg_result], 1)\n        output = self.conv(result)\n        output = self.sigmoid(output)\n        return output\n\n\nclass CBAMBlock(nn.Module):\n\n    def __init__(self, channel=512, reduction=16, kernel_size=49):\n        super().__init__()\n        self.ca = ChannelAttention(channel=channel, reduction=reduction)\n        self.sa = SpatialAttention(kernel_size=kernel_size)\n\n    def init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                init.kaiming_normal_(m.weight, mode='fan_out')\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                init.constant_(m.weight, 1)\n                init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                init.normal_(m.weight, std=0.001)\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        b, c, _, _ = x.size()\n        residual = x\n        out = x * self.ca(x)\n        out = out * self.sa(out)\n        return out + residual","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:31:04.454760Z","iopub.execute_input":"2021-12-30T05:31:04.455179Z","iopub.status.idle":"2021-12-30T05:31:04.476604Z","shell.execute_reply.started":"2021-12-30T05:31:04.455028Z","shell.execute_reply":"2021-12-30T05:31:04.475786Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Import the libraries\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms.functional as TF\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Defining the main Encoder decoder model using the double convolution class\nclass Vessel_net(nn.Module):\n    def __init__(self, in_channels=3, out_channels=1, features=[32,64,128]):\n        super(Vessel_net, self).__init__()\n        self.downs = nn.ModuleList()\n        self.ups = nn.ModuleList()\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.singleconv1 = SingleConv(in_channels=features[-1], out_channels=features[-1]*2)\n        self.singleconv2 = SingleConv(in_channels=features[-1]*2, out_channels=features[-1]*2)\n\n        # encoder part (down part)\n        for feature in features:\n            self.downs.append(DoubleConv(in_channels=in_channels, out_channels=feature))\n            in_channels = feature\n\n        # decoder part (up part)\n        for feature in reversed(features):\n            self.ups.append(\n                nn.ConvTranspose2d(in_channels=feature * 2,\n                                   out_channels=feature,\n                                   kernel_size=2,\n                                   stride=2\n                                   )\n            )\n            self.ups.append(\n                DoubleConv(in_channels=feature * 2, out_channels=feature)\n            )\n\n        self.bottleneck = CBAMBlock(channel=256)\n        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n\n    def forward(self, x):\n        skip_connections = []\n        for down in self.downs:\n            x = down(x)\n            skip_connections.append(x)\n            x = self.pool(x)\n\n\n        x=self.singleconv1(x)\n        x = self.bottleneck(x)\n        x=self.singleconv2(x)\n        #print('size before entering the decoder ' + str(x.size()))\n        # reverse the skip connection list\n        skip_connections = skip_connections[::-1]\n\n        for idx in range(0, len(self.ups), 2):\n            x = self.ups[idx](x)\n            skip_connection = skip_connections[idx // 2]\n\n            if x.shape != skip_connection.shape:\n                x = TF.resize(x, size=skip_connection.shape[2:])\n\n            concat_skip = torch.cat((skip_connection, x), dim=1)\n            x = self.ups[idx + 1](concat_skip)\n        x=self.final_conv(x)\n        return x\n\n\ndef test():\n    x = torch.randn((5, 3, 960, 960)).to(device)\n    model = Vessel_net(in_channels=3, out_channels=1).to(device)\n    preds = model(x).to(device)\n    total_params = sum(p.numel() for p in model.parameters())\n    #print(model)\n    print(\"Shape of the Input image\"+str(x.shape))\n    print(\"shape of the output segmentation map\"+str(preds.shape))\n\n    print(\"Number of Model Parameters:\", total_params)\n\n\n\nif __name__ == '__main__':\n    test()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:31:04.477956Z","iopub.execute_input":"2021-12-30T05:31:04.478334Z","iopub.status.idle":"2021-12-30T05:31:09.906152Z","shell.execute_reply.started":"2021-12-30T05:31:04.478298Z","shell.execute_reply":"2021-12-30T05:31:09.905374Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## training","metadata":{}},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:31:09.907593Z","iopub.execute_input":"2021-12-30T05:31:09.907850Z","iopub.status.idle":"2021-12-30T05:31:10.390284Z","shell.execute_reply.started":"2021-12-30T05:31:09.907820Z","shell.execute_reply":"2021-12-30T05:31:10.388610Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def forward_for_train(loss_func, target):\n     with torch.cuda.amp.autocast():\n            predictions = model(data)\n            loss = loss_fn(predictions, targets)\n            return loss\n        \ndef backward_for_train(loss, optimizer):\n    global running_loss\n    optimizer.zero_grad()\n    scaler.scale(loss).backward()\n    scaler.step(optimizer)\n    scaler.update()\n\n    img_grid = torchvision.utils.make_grid(data)\n    writer.add_image(\"Input_image\", img_grid)\n    # writer.add_histogram(\"fc1\", model.fc1.weight)\n    writer.add_scalar(\"Training Loss\", loss, global_step=step)\n        \n    loop.set_postfix(loss=loss.item())\n    running_loss += loss.item()\n       \n    return running_loss","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-12-30T05:31:10.391612Z","iopub.execute_input":"2021-12-30T05:31:10.391909Z","iopub.status.idle":"2021-12-30T05:31:10.401079Z","shell.execute_reply.started":"2021-12-30T05:31:10.391870Z","shell.execute_reply":"2021-12-30T05:31:10.400076Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import os\n\nimport torch\nimport torchvision\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom torch.utils.tensorboard.writer import SummaryWriter\nfrom tqdm import tqdm\nimport torch.nn as nn\nimport torch.optim as optim\n\ntorch.cuda.empty_cache()\n# loss_list = pd.DataFrame(columns=['Epoch_no','FocalTverskyLoss'])\n\ntrain_loss = 10000\n\nstep = 0\n\nlr=1e-5\nbatch_size=8\ndevice=\"cuda\"\nepochs= 50\nnum_workers=2\nheight=480\nwidth= 480\npin_memory=True\nload_model=False\n\ntrain_dir=\"../input/vesselnet-code/Data/Data/CHASE/CHASE_1000/train/image\"\ntrain_mask=\"../input/vesselnet-code/Data/Data/CHASE/CHASE_1000/train/label\"\nval_dir=\"../input/vesselnet-code/Data/Data/CHASE/CHASE_1000/validate/image\"\nval_mask=\"../input/vesselnet-code/Data/Data/CHASE/CHASE_1000/validate/label\"\ntest_dir=\"../input/vesselnet-code/Data/Data/CHASE/CHASE_1000/test/image\"\ntest_mask=\"../input/vesselnet-code/Data/Data/CHASE/CHASE_1000/test/label\"\nload_weights=\"./Vessel_Net_checkpoint.pth.tar\"\nprev_metrics_csv_dir='./prev_metrics.csv'\nmetrics_csv_dir = './new_metrics.csv'\n\n    \ndef train_fn(loader, model, optimizer, loss_fn, scaler, writer, epoch):\n    global train_loss\n    global step\n    loop = tqdm(loader)\n    \n    for batch_idx, (data, targets) in enumerate(loop):\n        data = data.to(device=device)\n        targets = targets.float().unsqueeze(1).to(device=device)\n        \n        # forward\n        with torch.cuda.amp.autocast():\n            predictions = model(data)\n            train_loss = loss_fn(predictions, targets)\n\n        # backward\n        optimizer.zero_grad()\n        scaler.scale(train_loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        img_grid = torchvision.utils.make_grid(data)\n        writer.add_image(\"Input_image\", img_grid)\n        # writer.add_histogram(\"fc1\", model.fc1.weight)\n        writer.add_scalar(\"Training Loss\", train_loss, global_step = step)\n        \n        # update tqdm loop\n        loop.set_postfix(loss=train_loss.item())\n        \n        step += 1\n        \n#     train_loss=running_loss/len(loader)\n#     new_loss = {'Epoch_no':epoch,'FocalTverskyLoss':train_loss}\n#     loss_list = loss_list.append(new_loss, ignore_index=True)\n    \n    \n    \ndef main():\n    global step,prediction\n    \n    if(os.path.isfile('metrics.csv')):\n        prediction = pd.read_csv('metrics.csv')\n        prediction.drop(prediction.columns[prediction.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n        \n    torch.cuda.empty_cache()\n    train_transform = A.Compose(\n        [\n            A.Resize(height=height, width=width),\n            A.Normalize(\n                mean=[0.0, 0.0, 0.0],\n                std=[1.0, 1.0, 1.0],\n                max_pixel_value=255.0,\n            ),\n            ToTensorV2(),\n        ],\n    )\n\n    val_transforms = A.Compose(\n        [\n            A.Resize(height=height, width=width),\n            A.Normalize(\n                mean=[0.0, 0.0, 0.0],\n                std=[1.0, 1.0, 1.0],\n                max_pixel_value=255.0,\n            ),\n            ToTensorV2(),\n        ],\n    )\n    model = Vessel_net(in_channels=3, out_channels=1).to(device)\n\n    train_loader, val_loader = get_loaders(\n        train_dir,\n        train_mask,\n        val_dir,\n        val_mask,\n        batch_size,\n        train_transform,\n        val_transforms,\n        num_workers,\n        pin_memory,\n    )\n\n    # since no sigmoid on the output of the model we use with logits\n    loss_fn = nn.BCEWithLogitsLoss() # for multiclass classification use cross entropy loss and change  #out_channels\n    \n    \n    optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=1e-04)\n    writer = SummaryWriter(\n       f\"runs/Dataset/Minibatch {batch_size} LR {lr}\" \n    )\n    \n    \n    images, _ = next(iter(train_loader))\n    writer.add_graph(model, images.to(device))\n    writer.close()\n\n    PREV_EPOCHS = 0\n    \n    if load_model:\n        PREV_EPOCHS = load_checkpoint(torch.load(\n            load_weights),\n            model)\n    print(\"Loaded Model Metrics\")\n\n    scaler = torch.cuda.amp.GradScaler()\n\n    for epoch in range(PREV_EPOCHS+1,epochs+1):\n        print(\"Epoch : \" + str(epoch))\n        train_fn(train_loader, model, optimizer, loss_fn, scaler, writer=writer, epoch=int(epoch))\n    \n        if epoch == (epochs):\n            last_epoch = True\n            checkpoint = {\n                    \"epoch\": epoch,\n                    \"state_dict\": model.state_dict(),\n                    \"optimizer\": optimizer.state_dict(),\n                    \"loss\": loss_fn,\n            }\n\n            # save model\n            checkpoint_name = './' + model_name + '_' + dataset_name + '_Epochs_' + str(epoch) + '_MODEL.pth.tar'\n            save_checkpoint(checkpoint, checkpoint_name)\n\n            # check accuracy\n            try:\n                os.mkdir('validation_saved_images')\n                os.mkdir('validation_saved_images/pred')\n                os.mkdir('validation_saved_images/truth_labels')\n            except:\n                print(\"Results directory already created\")\n                pass\n            save_predictions_as_imgs(val_loader, model, folder=\"validation_saved_images\", device=device)\n        else:\n            last_epoch = False\n        \n        print(\"Epoch Metrics are being printed for epoch num :\" + str(epoch))\n\n        check_metrics(train_loader,\n                      val_loader,\n                      model,\n                      device=device,\n                      epoch_no=int(epoch),\n                      last_epoch=last_epoch,\n                      loss_fn=loss_fn,\n                      train_loss=train_loss.item(),\n                      load_model=bool(load_model),\n                      writer={\"writer\": writer, \"step\": step},\n                      metrics_dir=metrics_csv_dir,\n                      prev_metrics_csv_dir=prev_metrics_csv_dir\n                      )\n        step += 1\n\n\n\n\n  \n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:31:10.403143Z","iopub.execute_input":"2021-12-30T05:31:10.403639Z","iopub.status.idle":"2021-12-30T05:31:11.938176Z","shell.execute_reply.started":"2021-12-30T05:31:10.403601Z","shell.execute_reply":"2021-12-30T05:31:11.937407Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# import os\n# import argparse\n# import torch\n# import torchvision\n# import albumentations as A\n# from albumentations.pytorch import ToTensorV2\n# from torch.utils.tensorboard.writer import SummaryWriter\n# from tqdm import tqdm\n# import torch.nn as nn\n# import torch.optim as optim\n\n# # from models.VesselNet import Vessel_net\n# # from results.metrics import check_metrics\n# # from utils import load_checkpoint, save_checkpoint, get_loaders, save_predictions_as_imgs\n\n# torch.cuda.empty_cache()\n\n# train_loss = 10000\n\n# step = 0\n\n# train_dir=\"../input/vesselnet-code/Data/Data/CHASE/CHASE_1000/train/image\"\n# train_mask=\"../input/vesselnet-code/Data/Data/CHASE/CHASE_1000/train/label\"\n# val_dir=\"../input/vesselnet-code/Data/Data/CHASE/CHASE_1000/validate/image\"\n# val_mask=\"../input/vesselnet-code/Data/Data/CHASE/CHASE_1000/validate/label\"\n# test_dir=\"../input/vesselnet-code/Data/Data/CHASE/CHASE_1000/test/image\"\n# test_mask=\"../input/vesselnet-code/Data/Data/CHASE/CHASE_1000/test/label\"\n# load_weights=\"./Vessel_Net_checkpoint.pth.tar\"\n\n\n\n\n# # USIng Mixed precision training (FP-16 used )\n# def train_fn(loader, model, optimizer, loss_fn, scaler, args, writer):\n#     global train_loss\n#     global step\n#     loop = tqdm(loader)\n#     for batch_idx, (data, targets) in enumerate(loop):\n#         data = data.to(device=args.device)\n#         targets = targets.float().unsqueeze(1).to(device=args.device)\n\n#         # forward\n#         with torch.cuda.amp.autocast():\n#             predictions = model(data)\n#             train_loss = loss_fn(predictions, targets)\n\n#         # backward\n#         optimizer.zero_grad()\n#         scaler.scale(train_loss).backward()\n#         scaler.step(optimizer)\n#         scaler.update()\n\n#         img_grid = torchvision.utils.make_grid(data)\n#         writer.add_image(\"Input_image\", img_grid)\n#         # writer.add_histogram(\"fc1\", model.fc1.weight)\n#         writer.add_scalar(\"Training Loss\", train_loss, global_step=step)\n\n#         # update tqdm loop\n#         loop.set_postfix(loss=train_loss.item())\n\n#         step += 1\n\n\n# def main(args):\n#     global step\n#     torch.cuda.empty_cache()\n#     train_transform = A.Compose(\n#         [\n#             A.Resize(height=args.height, width=args.width),\n#             A.Normalize(\n#                 mean=[0.0, 0.0, 0.0],\n#                 std=[1.0, 1.0, 1.0],\n#                 max_pixel_value=255.0,\n#             ),\n#             ToTensorV2(),\n#         ],\n#     )\n\n#     val_transforms = A.Compose(\n#         [\n#             A.Resize(height=args.height, width=args.width),\n#             A.Normalize(\n#                 mean=[0.0, 0.0, 0.0],\n#                 std=[1.0, 1.0, 1.0],\n#                 max_pixel_value=255.0,\n#             ),\n#             ToTensorV2(),\n#         ],\n#     )\n#     model = Vessel_net(in_channels=3, out_channels=1).to(args.device)\n\n#     train_loader, val_loader = get_loaders(\n#         args.train_dir,\n#         args.train_mask,\n#         args.val_dir,\n#         args.val_mask,\n#         args.batch_size,\n#         train_transform,\n#         val_transforms,\n#         args.num_workers,\n#         args.pin_memory,\n#     )\n\n#     # since no sigmoid on the output of the model we use with logits\n#     loss_fn = nn.BCEWithLogitsLoss()  # for multiclass classification use cross entropy loss and change  #out_channels\n#     optimizer = optim.Adam(model.parameters(), lr=args.lr,weight_decay=1e-04)\n#     writer = SummaryWriter(\n#         f\"runs/Dataset/Minibatch {args.batch_size} LR {args.lr}\"\n#     )\n\n#     images, _ = next(iter(train_loader))\n#     writer.add_graph(model, images.to(args.device))\n#     writer.close()\n\n\n#     PREV_EPOCHS = 0\n\n\n#     if args.load_model:\n#         PREV_EPOCHS = load_checkpoint(torch.load(\n#             args.load_weights),\n#             model)\n#         print(\"Loaded Model Metrics\")\n#         #print(\"Epoch Metrics are being printed for epoch num :\"+str(PREV_EPOCHS))\n#         #check_metrics(loader=val_loader, model=model, device=args.device,epoch_no=PREV_EPOCHS, writer={\"writer\": writer, \"step\": step},last_epoch= False,load_model= args.load_model)\n\n\n#     scaler = torch.cuda.amp.GradScaler()\n\n\n#     for epoch in range(PREV_EPOCHS+1,args.epochs+1):\n\n#         print(\"Epoch : \" + str(epoch))\n\n#         train_fn(train_loader, model, optimizer, loss_fn, scaler, args, writer=writer)\n\n#         # save model and predictions\n#         if epoch == (args.epochs):\n#             last_epoch = True\n#             checkpoint = {\n#                 \"epoch\": epoch,\n#                 \"state_dict\": model.state_dict(),\n#                 \"optimizer\": optimizer.state_dict(),\n#                 \"loss\": loss_fn,\n#             }\n\n\n#             checkpoint_name = './'+args.model_name+'_'+args.dataset_name+'_Epochs_' + str(epoch) + '_MODEL.pth.tar'\n#             save_checkpoint(checkpoint, checkpoint_name)\n#             try:\n#                 os.mkdir('validation_saved_images')\n#                 os.mkdir('validation_saved_images/pred')\n#                 os.mkdir('validation_saved_images/truth_labels')\n#             except:\n#                 print(\"Results directory already created\")\n#                 pass\n#             save_predictions_as_imgs(val_loader, model, folder=\"validation_saved_images\", device=args.device)\n#         else:\n#             last_epoch = False\n#         #CHECK METRICS\n#         print(\"Epoch Metrics are being printed for epoch num :\" + str(epoch))\n\n#         check_metrics(train_loader,\n#                       val_loader,\n#                       model,\n#                       device=args.device,\n#                       epoch_no=int(epoch),\n#                       last_epoch=last_epoch,\n#                       loss_fn=loss_fn,\n#                       train_loss=train_loss.item(),\n#                       load_model=bool(args.load_model),\n#                       writer={\"writer\": writer, \"step\": step},\n#                       metrics_dir=args.metrics_csv_dir,\n#                       prev_metrics_csv_dir=args.prev_metrics_csv_dir\n#                       )\n#         step += 1\n\n\n\n\n    \n","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-12-30T05:31:11.939520Z","iopub.execute_input":"2021-12-30T05:31:11.939764Z","iopub.status.idle":"2021-12-30T05:31:11.948082Z","shell.execute_reply.started":"2021-12-30T05:31:11.939733Z","shell.execute_reply":"2021-12-30T05:31:11.947443Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# if __name__ == \"__main__\":\n#     parser = argparse.ArgumentParser()\n#     parser.add_argument(\"--model_name\", default=\"VesselNet\", type=str, help=\"Name of the saved model\")\n#     parser.add_argument(\"--dataset_name\", default=\"CHASE\", type=str, help=\"Name of the data set used\")\n#     parser.add_argument(\"--lr\", default=1e-3, type=float, help=\"Learning Rate for training\")\n#     parser.add_argument(\"--batch_size\", default=4, type=int, help=\"Batch Size for training\")\n#     parser.add_argument(\"--device\", default=\"cuda\", help=\"cuda or cpu\")\n#     parser.add_argument(\"--epochs\", default=5, type=int, help=\"Number of Epochs\")\n#     parser.add_argument(\"--num_workers\", default=2, help=\"Number of workers\")\n#     parser.add_argument(\"--height\", default=256, type=int, help=\"Input Image Height\")\n#     parser.add_argument(\"--width\", default=56, type=int, help=\"Input Image width\")\n#     parser.add_argument(\"--pin_memory\", default=True, help=\"Pin Memory\")\n#     parser.add_argument(\"--load_model\",type=bool, default=False, help=\"Load Pretrained Model\")\n#     parser.add_argument(\"--train_dir\", default=train_dir, type=str,\n#                         help=\"Training images directory\")\n#     parser.add_argument(\"--train_mask\", default=train_mask, type=str,\n#                         help=\"Training mask directory\")\n#     parser.add_argument(\"--val_dir\", default=val_dir, type=str,\n#                         help=\"Validation Image directory\")\n#     parser.add_argument(\"--val_mask\", type=str, default=val_mask,\n#                         help=\"Validation label directory\")\n#     parser.add_argument(\"--test_dir\", default=test_dir, type=str,\n#                         help=\"Test image directory\")\n#     parser.add_argument(\"--test_mask\", default=test_mask, type=str,\n#                         help=\"Test mask directory\")\n#     parser.add_argument(\"--load_weights\", default=\"trained.pth.tar\", type=str, help=\"Add training weight path.\")\n#     parser.add_argument(\"--metrics_csv_dir\",default=\"./new_metrics.csv\",type=str,help=\"File path to the metrics csv file.\")\n#     parser.add_argument(\"--prev_metrics_csv_dir\", default=\"./prev_metrics.csv\", type=str,\n#                         help=\"File path to the metrics csv file of the prev loaded model.\")\n# args = parser.parse_args()","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-12-30T05:31:11.949408Z","iopub.execute_input":"2021-12-30T05:31:11.949916Z","iopub.status.idle":"2021-12-30T05:31:11.962511Z","shell.execute_reply.started":"2021-12-30T05:31:11.949880Z","shell.execute_reply":"2021-12-30T05:31:11.961740Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"\n# Saving to csv","metadata":{}},{"cell_type":"code","source":"def convert_to_csv(prediction, file_name):\n    if(os.path.isfile(file_name)):\n        os.remove(file_name)\n    prediction.to_csv(file_name, header=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:31:11.964059Z","iopub.execute_input":"2021-12-30T05:31:11.964464Z","iopub.status.idle":"2021-12-30T05:31:11.974185Z","shell.execute_reply.started":"2021-12-30T05:31:11.964425Z","shell.execute_reply":"2021-12-30T05:31:11.973509Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\ndef plotting_metrics(Results_dataframe):\n    try:\n        os.mkdir('./metrics_plots')\n\n    except:\n        print(\" Metrics Plots directory already created\")\n        pass\n\n    # accuracy\n    fig, ax = plt.subplots(figsize=(8, 8))\n    sns.lineplot(x='Epoch_no', y='Train_Accuracy', data=Results_dataframe, color='red')\n    sns.lineplot(x='Epoch_no', y='Val_Accuracy', data=Results_dataframe, color='blue')\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.title(\"Accuracy Graph\")\n    plt.legend([\"Train\", \"Val\"], loc=\"upper right\")\n\n    plt.savefig('./metrics_plots/accuracy.png', dpi=300, bbox_inches='tight')\n    plt.close()\n\n    # IOU\n    fig, ax = plt.subplots(figsize=(8, 8))\n    sns.lineplot(x='Epoch_no', y='Train_IoU', data=Results_dataframe, color='red')\n    sns.lineplot(x='Epoch_no', y='Val_IoU', data=Results_dataframe, color='blue')\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"IoU\")\n    plt.title(\"IoU Score\")\n    plt.legend([\"Train\", \"Val\"], loc=\"upper right\")\n\n    plt.savefig('./metrics_plots/IoU.png', dpi=300, bbox_inches='tight')\n    plt.close()\n\n    # Dice\n    fig, ax = plt.subplots(figsize=(8, 8))\n    sns.lineplot(x='Epoch_no', y='Train_Dice', data=Results_dataframe, color='red')\n    sns.lineplot(x='Epoch_no', y='Val_Dice', data=Results_dataframe, color='blue')\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Dice\")\n    plt.title(\"Dice\")\n    plt.legend([\"Train\", \"Val\"], loc=\"upper right\")\n\n    plt.savefig('./metrics_plots/dice.png', dpi=300, bbox_inches='tight')\n    plt.close()\n\n    # f1_score\n    fig, ax = plt.subplots(figsize=(8, 8))\n    sns.lineplot(x='Epoch_no', y='Train_f1_score', data=Results_dataframe, color='red')\n    sns.lineplot(x='Epoch_no', y='Val_f1_score', data=Results_dataframe, color='blue')\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"F1 score\")\n    plt.title(\"F1 score\")\n    plt.legend([\"Train\", \"Val\"], loc=\"upper right\")\n\n    plt.savefig('./metrics_plots/f1_score.png', dpi=300, bbox_inches='tight')\n    plt.close()\n\n    # Precision\n    fig, ax = plt.subplots(figsize=(8, 8))\n    sns.lineplot(x='Epoch_no', y='Train_Precision', data=Results_dataframe, color='red')\n    sns.lineplot(x='Epoch_no', y='Val_Precision', data=Results_dataframe, color='blue')\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Precision\")\n    plt.title(\"Precision\")\n    plt.legend([\"Train\", \"Val\"], loc=\"upper right\")\n\n    plt.savefig('./metrics_plots/precision.png', dpi=300, bbox_inches='tight')\n    plt.close()\n    plt.legend([\"Train\", \"Val\"], loc=\"upper right\")\n\n    # Recall\n    fig, ax = plt.subplots(figsize=(8, 8))\n    sns.lineplot(x='Epoch_no', y='Train_Recall', data=Results_dataframe, color='red')\n    sns.lineplot(x='Epoch_no', y='Val_Recall', data=Results_dataframe, color='blue')\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Recall\")\n    plt.title(\"Recall\")\n    plt.legend([\"Train\", \"Val\"], loc=\"upper right\")\n\n    plt.savefig('./metrics_plots/recall.png', dpi=300, bbox_inches='tight')\n    plt.close()\n\n    # Specificity\n    fig, ax = plt.subplots(figsize=(8, 8))\n    sns.lineplot(x='Epoch_no', y='Train_Specificity', data=Results_dataframe, color='red')\n    sns.lineplot(x='Epoch_no', y='Val_Specificity', data=Results_dataframe, color='blue')\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Specificity\")\n    plt.title(\"Specificity\")\n    plt.legend([\"Train\", \"Val\"], loc=\"upper right\")\n\n    plt.savefig('./metrics_plots/specificity.png', dpi=300, bbox_inches='tight')\n    plt.close()\n\n    # MCC\n    fig, ax = plt.subplots(figsize=(8, 8))\n    sns.lineplot(x='Epoch_no', y='Train_MCC', data=Results_dataframe, color='red')\n    sns.lineplot(x='Epoch_no', y='Val_MCC', data=Results_dataframe, color='blue')\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"MCC\")\n    plt.title(\"MCC Score\")\n    plt.legend([\"Train\", \"Val\"], loc=\"upper right\")\n\n    plt.savefig('./metrics_plots/MCC.png', dpi=300, bbox_inches='tight')\n    plt.close()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:31:11.975570Z","iopub.execute_input":"2021-12-30T05:31:11.976043Z","iopub.status.idle":"2021-12-30T05:31:12.002776Z","shell.execute_reply.started":"2021-12-30T05:31:11.976007Z","shell.execute_reply":"2021-12-30T05:31:12.001979Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"main()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot Training and Validation loss vs EPOCHS\ndef plot_loss(dataframe):\n    # IOU\n    fig, ax = plt.subplots(figsize=(8, 8))\n    sns.lineplot(x='Epoch_no', y='Train_loss', data=dataframe, color='red')\n    sns.lineplot(x='Epoch_no', y='Val_loss', data=dataframe, color='blue')\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"LOSS vs EPOCH\")\n    plt.legend([\"Train\", \"Val\"], loc=\"upper right\")\n    plt.savefig('./metrics_plots/loss.png', dpi=300, bbox_inches='tight')\n    plt.close()\n\n\n# function to convert it to csv file\ndef convert_to_csv(prediction, metrics_dir):\n    prediction.to_csv(metrics_dir, header=True, index=False)\n\n\nif __name__ == \"__main__\":\n    # Test Metric Plotting\n    metrics_dir_path = 'metrics_plots'\n    Results_dataframe = pd.read_csv(metrics_dir_path, index_col=False)\n    # plotting_metrics(Results_dataframe)\n    plot_loss(Results_dataframe)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:31:12.003853Z","iopub.execute_input":"2021-12-30T05:31:12.004248Z","iopub.status.idle":"2021-12-30T05:31:12.201592Z","shell.execute_reply.started":"2021-12-30T05:31:12.004213Z","shell.execute_reply":"2021-12-30T05:31:12.200344Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"Results_dataframe = pd.read_csv(metrics_dir, index_col=False)\nplotting_metrics(Results_dataframe)\nplot_loss(Results_dataframe)","metadata":{},"execution_count":null,"outputs":[]}]}